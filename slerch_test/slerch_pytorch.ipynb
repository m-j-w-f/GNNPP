{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNPP\n",
    "This Notebook reimplements the Method of the Paper from RL 18 to compare results to the pytoch geometric model.\n",
    "This should archieve a CRPS score around 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T22:04:36.075980Z",
     "start_time": "2023-07-04T22:04:36.073316Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "import helpers\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import trange\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T22:04:45.615633Z",
     "start_time": "2023-07-04T22:04:36.080376Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data ...\n",
      "Cleaning Data ...\n"
     ]
    }
   ],
   "source": [
    "# read data (can be downloaded from https://doi.org/10.6084/m9.figshare.13516301.v1)\n",
    "print(\"Loading Data ...\")\n",
    "data = helpers.load_data(indexed=False)\n",
    "\n",
    "print(\"Cleaning Data ...\")\n",
    "data = helpers.clean_data(data, max_missing=121, max_alt=1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T22:04:45.923413Z",
     "start_time": "2023-07-04T22:04:45.614389Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station</th>\n",
       "      <th>obs</th>\n",
       "      <th>t2m_mean</th>\n",
       "      <th>t2m_var</th>\n",
       "      <th>cape_mean</th>\n",
       "      <th>cape_var</th>\n",
       "      <th>sp_mean</th>\n",
       "      <th>sp_var</th>\n",
       "      <th>tcc_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>str_var</th>\n",
       "      <th>d2m_mean</th>\n",
       "      <th>d2m_var</th>\n",
       "      <th>sm_mean</th>\n",
       "      <th>sm_var</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>alt</th>\n",
       "      <th>orog</th>\n",
       "      <th>doy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-03 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.616448</td>\n",
       "      <td>0.079733</td>\n",
       "      <td>11.480126</td>\n",
       "      <td>164.398999</td>\n",
       "      <td>101263.773906</td>\n",
       "      <td>17346.641356</td>\n",
       "      <td>46.793524</td>\n",
       "      <td>...</td>\n",
       "      <td>2.810124e+11</td>\n",
       "      <td>275.956692</td>\n",
       "      <td>0.151394</td>\n",
       "      <td>318.990796</td>\n",
       "      <td>6.543392</td>\n",
       "      <td>50.782700</td>\n",
       "      <td>6.0941</td>\n",
       "      <td>202.0</td>\n",
       "      <td>107.439461</td>\n",
       "      <td>-0.983798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-03 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.601281</td>\n",
       "      <td>0.107129</td>\n",
       "      <td>22.207007</td>\n",
       "      <td>207.708022</td>\n",
       "      <td>101463.529063</td>\n",
       "      <td>18411.594667</td>\n",
       "      <td>48.161629</td>\n",
       "      <td>...</td>\n",
       "      <td>2.771202e+11</td>\n",
       "      <td>275.529611</td>\n",
       "      <td>0.152089</td>\n",
       "      <td>325.635452</td>\n",
       "      <td>8.776818</td>\n",
       "      <td>52.485298</td>\n",
       "      <td>7.9126</td>\n",
       "      <td>65.0</td>\n",
       "      <td>47.632523</td>\n",
       "      <td>-0.983798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-03 00:00:00+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.873910</td>\n",
       "      <td>0.078148</td>\n",
       "      <td>44.308516</td>\n",
       "      <td>1438.915507</td>\n",
       "      <td>97942.360781</td>\n",
       "      <td>20106.971594</td>\n",
       "      <td>63.223506</td>\n",
       "      <td>...</td>\n",
       "      <td>4.909704e+11</td>\n",
       "      <td>275.008204</td>\n",
       "      <td>0.075718</td>\n",
       "      <td>336.861672</td>\n",
       "      <td>5.635509</td>\n",
       "      <td>50.744598</td>\n",
       "      <td>9.3450</td>\n",
       "      <td>300.0</td>\n",
       "      <td>348.869904</td>\n",
       "      <td>-0.983798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-03 00:00:00+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.718213</td>\n",
       "      <td>0.198263</td>\n",
       "      <td>96.170580</td>\n",
       "      <td>2550.754359</td>\n",
       "      <td>98045.333437</td>\n",
       "      <td>19122.337645</td>\n",
       "      <td>73.738330</td>\n",
       "      <td>...</td>\n",
       "      <td>7.963386e+11</td>\n",
       "      <td>274.732042</td>\n",
       "      <td>0.186014</td>\n",
       "      <td>324.187435</td>\n",
       "      <td>13.339768</td>\n",
       "      <td>51.088100</td>\n",
       "      <td>12.9326</td>\n",
       "      <td>296.0</td>\n",
       "      <td>296.839203</td>\n",
       "      <td>-0.983798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-01-03 00:00:00+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.375332</td>\n",
       "      <td>0.149906</td>\n",
       "      <td>123.618650</td>\n",
       "      <td>1533.808489</td>\n",
       "      <td>96637.034219</td>\n",
       "      <td>16800.454370</td>\n",
       "      <td>91.842461</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033478e+12</td>\n",
       "      <td>274.021844</td>\n",
       "      <td>0.207122</td>\n",
       "      <td>315.014949</td>\n",
       "      <td>20.406193</td>\n",
       "      <td>48.405998</td>\n",
       "      <td>11.3117</td>\n",
       "      <td>510.0</td>\n",
       "      <td>461.575287</td>\n",
       "      <td>-0.983798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808680</th>\n",
       "      <td>2016-12-31 00:00:00+00:00</td>\n",
       "      <td>530</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.155651</td>\n",
       "      <td>0.978417</td>\n",
       "      <td>0.201357</td>\n",
       "      <td>0.141017</td>\n",
       "      <td>102826.477656</td>\n",
       "      <td>9997.686018</td>\n",
       "      <td>49.609571</td>\n",
       "      <td>...</td>\n",
       "      <td>1.132820e+12</td>\n",
       "      <td>271.254705</td>\n",
       "      <td>1.372146</td>\n",
       "      <td>245.919016</td>\n",
       "      <td>17.199589</td>\n",
       "      <td>52.715599</td>\n",
       "      <td>7.3176</td>\n",
       "      <td>19.0</td>\n",
       "      <td>36.652340</td>\n",
       "      <td>-0.973264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808940</th>\n",
       "      <td>2016-12-31 00:00:00+00:00</td>\n",
       "      <td>531</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>-3.497557</td>\n",
       "      <td>0.172615</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>96513.425000</td>\n",
       "      <td>4798.146479</td>\n",
       "      <td>0.186227</td>\n",
       "      <td>...</td>\n",
       "      <td>1.159146e+11</td>\n",
       "      <td>266.253950</td>\n",
       "      <td>0.827402</td>\n",
       "      <td>395.544220</td>\n",
       "      <td>22.223388</td>\n",
       "      <td>48.441799</td>\n",
       "      <td>9.9216</td>\n",
       "      <td>593.0</td>\n",
       "      <td>532.696167</td>\n",
       "      <td>-0.973264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808533</th>\n",
       "      <td>2016-12-31 00:00:00+00:00</td>\n",
       "      <td>532</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>-1.661223</td>\n",
       "      <td>0.163165</td>\n",
       "      <td>0.021574</td>\n",
       "      <td>0.006121</td>\n",
       "      <td>102359.503125</td>\n",
       "      <td>8667.898487</td>\n",
       "      <td>7.431432</td>\n",
       "      <td>...</td>\n",
       "      <td>1.425973e+11</td>\n",
       "      <td>269.773757</td>\n",
       "      <td>0.461191</td>\n",
       "      <td>253.349395</td>\n",
       "      <td>13.011937</td>\n",
       "      <td>51.841801</td>\n",
       "      <td>8.0607</td>\n",
       "      <td>104.0</td>\n",
       "      <td>95.691666</td>\n",
       "      <td>-0.973264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808941</th>\n",
       "      <td>2016-12-31 00:00:00+00:00</td>\n",
       "      <td>533</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-5.979924</td>\n",
       "      <td>0.349577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95704.712813</td>\n",
       "      <td>4314.376743</td>\n",
       "      <td>1.796408</td>\n",
       "      <td>...</td>\n",
       "      <td>6.356090e+10</td>\n",
       "      <td>263.174088</td>\n",
       "      <td>0.838257</td>\n",
       "      <td>353.039061</td>\n",
       "      <td>22.348963</td>\n",
       "      <td>47.876099</td>\n",
       "      <td>10.5848</td>\n",
       "      <td>816.0</td>\n",
       "      <td>671.567078</td>\n",
       "      <td>-0.973264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808582</th>\n",
       "      <td>2016-12-31 00:00:00+00:00</td>\n",
       "      <td>534</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-4.318435</td>\n",
       "      <td>0.096924</td>\n",
       "      <td>0.089892</td>\n",
       "      <td>0.038259</td>\n",
       "      <td>97900.696563</td>\n",
       "      <td>4972.161398</td>\n",
       "      <td>1.182946</td>\n",
       "      <td>...</td>\n",
       "      <td>1.488956e+11</td>\n",
       "      <td>266.343578</td>\n",
       "      <td>0.280225</td>\n",
       "      <td>350.314387</td>\n",
       "      <td>13.186273</td>\n",
       "      <td>48.487801</td>\n",
       "      <td>10.2607</td>\n",
       "      <td>444.0</td>\n",
       "      <td>507.198090</td>\n",
       "      <td>-0.973264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1641095 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             date  station  obs  t2m_mean   t2m_var  \\\n",
       "0       2007-01-03 00:00:00+00:00        0  5.5  3.616448  0.079733   \n",
       "1       2007-01-03 00:00:00+00:00        1  2.9  4.601281  0.107129   \n",
       "2       2007-01-03 00:00:00+00:00        2  3.3  2.873910  0.078148   \n",
       "4       2007-01-03 00:00:00+00:00        4  3.4  2.718213  0.198263   \n",
       "5       2007-01-03 00:00:00+00:00        5  1.8  1.375332  0.149906   \n",
       "...                           ...      ...  ...       ...       ...   \n",
       "1808680 2016-12-31 00:00:00+00:00      530 -0.6 -0.155651  0.978417   \n",
       "1808940 2016-12-31 00:00:00+00:00      531 -5.3 -3.497557  0.172615   \n",
       "1808533 2016-12-31 00:00:00+00:00      532 -2.7 -1.661223  0.163165   \n",
       "1808941 2016-12-31 00:00:00+00:00      533 -1.5 -5.979924  0.349577   \n",
       "1808582 2016-12-31 00:00:00+00:00      534 -3.5 -4.318435  0.096924   \n",
       "\n",
       "          cape_mean     cape_var        sp_mean        sp_var   tcc_mean  ...  \\\n",
       "0         11.480126   164.398999  101263.773906  17346.641356  46.793524  ...   \n",
       "1         22.207007   207.708022  101463.529063  18411.594667  48.161629  ...   \n",
       "2         44.308516  1438.915507   97942.360781  20106.971594  63.223506  ...   \n",
       "4         96.170580  2550.754359   98045.333437  19122.337645  73.738330  ...   \n",
       "5        123.618650  1533.808489   96637.034219  16800.454370  91.842461  ...   \n",
       "...             ...          ...            ...           ...        ...  ...   \n",
       "1808680    0.201357     0.141017  102826.477656   9997.686018  49.609571  ...   \n",
       "1808940    0.003596     0.000317   96513.425000   4798.146479   0.186227  ...   \n",
       "1808533    0.021574     0.006121  102359.503125   8667.898487   7.431432  ...   \n",
       "1808941    0.000000     0.000000   95704.712813   4314.376743   1.796408  ...   \n",
       "1808582    0.089892     0.038259   97900.696563   4972.161398   1.182946  ...   \n",
       "\n",
       "              str_var    d2m_mean   d2m_var     sm_mean     sm_var        lat  \\\n",
       "0        2.810124e+11  275.956692  0.151394  318.990796   6.543392  50.782700   \n",
       "1        2.771202e+11  275.529611  0.152089  325.635452   8.776818  52.485298   \n",
       "2        4.909704e+11  275.008204  0.075718  336.861672   5.635509  50.744598   \n",
       "4        7.963386e+11  274.732042  0.186014  324.187435  13.339768  51.088100   \n",
       "5        1.033478e+12  274.021844  0.207122  315.014949  20.406193  48.405998   \n",
       "...               ...         ...       ...         ...        ...        ...   \n",
       "1808680  1.132820e+12  271.254705  1.372146  245.919016  17.199589  52.715599   \n",
       "1808940  1.159146e+11  266.253950  0.827402  395.544220  22.223388  48.441799   \n",
       "1808533  1.425973e+11  269.773757  0.461191  253.349395  13.011937  51.841801   \n",
       "1808941  6.356090e+10  263.174088  0.838257  353.039061  22.348963  47.876099   \n",
       "1808582  1.488956e+11  266.343578  0.280225  350.314387  13.186273  48.487801   \n",
       "\n",
       "             lon    alt        orog       doy  \n",
       "0         6.0941  202.0  107.439461 -0.983798  \n",
       "1         7.9126   65.0   47.632523 -0.983798  \n",
       "2         9.3450  300.0  348.869904 -0.983798  \n",
       "4        12.9326  296.0  296.839203 -0.983798  \n",
       "5        11.3117  510.0  461.575287 -0.983798  \n",
       "...          ...    ...         ...       ...  \n",
       "1808680   7.3176   19.0   36.652340 -0.973264  \n",
       "1808940   9.9216  593.0  532.696167 -0.973264  \n",
       "1808533   8.0607  104.0   95.691666 -0.973264  \n",
       "1808941  10.5848  816.0  671.567078 -0.973264  \n",
       "1808582  10.2607  444.0  507.198090 -0.973264  \n",
       "\n",
       "[1641095 rows x 44 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1469770"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index of last day in 2015\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "idx = max(data[data.date.dt.year == 2015].index)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T22:04:46.048513Z",
     "start_time": "2023-07-04T22:04:46.044286Z"
    }
   },
   "outputs": [],
   "source": [
    "# split into train and test data\n",
    "eval_start = idx+1\n",
    "train_end = idx # 2016-12-01\n",
    "\n",
    "train_features_raw = data.iloc[:train_end,3:].to_numpy()\n",
    "train_targets = data.iloc[:train_end,2].to_numpy()\n",
    "train_IDs = data.iloc[:train_end,1].to_numpy()\n",
    "\n",
    "test_features_raw = data.iloc[eval_start:,3:].to_numpy()\n",
    "test_targets = data.iloc[eval_start:,2].to_numpy()\n",
    "test_IDs = data.iloc[eval_start:,1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T22:04:47.147666Z",
     "start_time": "2023-07-04T22:04:46.044406Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalize data\n",
    "def normalize(data, method=None, shift=None, scale=None):\n",
    "    result = np.zeros(data.shape)\n",
    "    if method == \"MAX\":\n",
    "        scale = np.max(data, axis=0)\n",
    "        shift = np.zeros(scale.shape)\n",
    "    for index in range(len(data[0])):\n",
    "        result[:,index] = (data[:,index] - shift[index]) / scale[index]\n",
    "    return result, shift, scale\n",
    "\n",
    "train_features, train_shift, train_scale = normalize(train_features_raw[:,:], method=\"MAX\")\n",
    "\n",
    "test_features = normalize(test_features_raw[:,:], shift=train_shift, scale=train_scale)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Neural Newtork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T22:04:47.147855Z",
     "start_time": "2023-07-04T22:04:47.145965Z"
    }
   },
   "outputs": [],
   "source": [
    "def crps(mu_sigma: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Calculates the Continuous Ranked Probability Score (CRPS) assuming normally distributed df\n",
    "\n",
    "    :param torch.Tensor mu_sigma: tensor of mean and standard deviation\n",
    "    :param torch.Tensor y: observed df\n",
    "\n",
    "    :return tensor: CRPS value\n",
    "    :rtype torch.Tensor\n",
    "    \"\"\"\n",
    "    mu, sigma = torch.split(mu_sigma, 1, dim=-1)\n",
    "    y = y.view((-1,1)) # make sure y has the right shape\n",
    "    pi = np.pi #3.14159265359\n",
    "    omega = (y - mu) / sigma\n",
    "    # PDF of normal distribution at omega\n",
    "    pdf = 1/(torch.sqrt(torch.tensor(2 * pi))) * torch.exp(-0.5 * omega ** 2)\n",
    "\n",
    "    # Source: https://stats.stackexchange.com/questions/187828/how-are-the-error-function-and-standard-normal-distribution-function-related\n",
    "    cdf = 0.5 * (1 + torch.erf(omega / torch.sqrt(torch.tensor(2))))\n",
    "\n",
    "    crps_score = sigma * (omega * (2 * cdf - 1) + 2 * pdf - 1/torch.sqrt(torch.tensor(pi)))\n",
    "    return  torch.mean(crps_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T22:04:47.169842Z",
     "start_time": "2023-07-04T22:04:47.146208Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class NNPP(nn.Module):\n",
    "    def __init__(self, INPUT_DIM:int):\n",
    "        super(NNPP, self).__init__()\n",
    "        self.emb = nn.Embedding(num_embeddings=535, embedding_dim=2)\n",
    "        self.lin1 = nn.Linear(in_features=INPUT_DIM+2, out_features=512)\n",
    "        self.lin2 = nn.Linear(in_features=512, out_features=2)\n",
    "\n",
    "    def forward(self, x, id):\n",
    "        emb_station = self.emb(id)\n",
    "        x = torch.cat((emb_station, x), dim=1) # Concatenate embedded station_id to rest of the feature vector\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Convert numpy arrays to tensors and put it in GPU memory for faster training\n",
    "train_features = torch.tensor(train_features, dtype=torch.float32).to(device)\n",
    "train_targets = torch.tensor(train_targets, dtype=torch.float32).to(device)\n",
    "train_IDs = torch.tensor(train_IDs, dtype=torch.int32).to(device)\n",
    "\n",
    "test_features = torch.tensor(test_features, dtype=torch.float32).to(device)\n",
    "test_targets = torch.tensor(test_targets, dtype=torch.float32).to(device)\n",
    "test_IDs = torch.tensor(test_IDs, dtype=torch.int32).to(device)\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 4096\n",
    "# Create a DataLoader\n",
    "class DatasetWithID(Dataset):\n",
    "    def __init__(self, train_target, train_id, train_feature):\n",
    "        self.train_target = train_target\n",
    "        self.train_id = train_id\n",
    "        self.train_features = train_feature\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_target)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.train_features[index]\n",
    "        id = self.train_id[index]\n",
    "        y = self.train_target[index]\n",
    "        return x, id, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T22:12:28.266013Z",
     "start_time": "2023-07-04T22:04:47.169555Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8077233575639271]\n",
      "Average Test Loss: 0.8077233575639271\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DatasetWithID(train_targets, train_IDs, train_features)\n",
    "test_dataset = DatasetWithID(test_targets, test_IDs, test_features)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def train(epochs:int, model, optimizer):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    test_loss = 0\n",
    "    # Train\n",
    "    epochs_bar = trange(epochs, desc=f\"Training Model {e}\", leave=False)\n",
    "    \n",
    "    for epoch in epochs_bar:\n",
    "        for x, id, y in train_loader:\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            mu_sigma = model(x, id)\n",
    "            # Compute the loss\n",
    "            loss = crps(mu_sigma, y)\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Add Loss\n",
    "            epoch_loss += loss.item()\n",
    "        epoch_loss /= len(train_loader)\n",
    "    epochs_bar.close()\n",
    "\n",
    "    #Eval\n",
    "    with torch.inference_mode():\n",
    "        for x, id, y in test_loader:\n",
    "            # Forward pass\n",
    "            mu_sigma = model(x, id)\n",
    "            # Compute the loss\n",
    "            loss = crps(mu_sigma, y)\n",
    "            # Add Loss\n",
    "            test_loss += loss.item()\n",
    "    test_loss /= len(test_loader)\n",
    "    return test_loss\n",
    "\n",
    "\n",
    "# Train Ensemble\n",
    "model_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "trn_scores = []\n",
    "test_scores = []\n",
    "preds = []\n",
    "\n",
    "nreps = 1\n",
    "\n",
    "for e in range(nreps):\n",
    "    model = NNPP(INPUT_DIM=test_features.shape[1])\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "    loss = train(epochs=15,\n",
    "                 model=model,\n",
    "                 optimizer=optimizer)\n",
    "    model_list.append(model)\n",
    "    test_loss_list.append(loss)\n",
    "print(test_loss_list)\n",
    "print(f\"Average Test Loss: {np.mean(test_loss_list)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
